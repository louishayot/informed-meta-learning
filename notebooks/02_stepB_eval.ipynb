{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step B — Evaluate under knowledge corruption\n",
    "\n",
    "Loads Step A checkpoints (sinusoids, abc2) and evaluates Predictive NLL (IS-NLL)\n",
    "under 4 corruption regimes: `clean`, `noisy_low`, `noisy_high`, `permuted`.\n",
    "\n",
    "For each regime, evaluation is done at context sizes C ∈ {0, 3, 5, 10}.\n",
    "\n",
    "Exports:\n",
    "- Per-run: `outputs/{run_name}/stepB_{mode}.json`\n",
    "- Aggregated: `outputs/stepB_eval.json` + `outputs/stepB_eval.tsv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /Users/louishayot/MVA/VdS_Submission_Final\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "_d = os.getcwd()\n",
    "while _d != os.path.dirname(_d):\n",
    "    if os.path.isfile(os.path.join(_d, 'config.py')):\n",
    "        break\n",
    "    _d = os.path.dirname(_d)\n",
    "REPO_ROOT = _d\n",
    "\n",
    "os.chdir(REPO_ROOT)\n",
    "if REPO_ROOT not in sys.path:\n",
    "    sys.path.insert(0, REPO_ROOT)\n",
    "\n",
    "print(f'Working directory: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "import random\n",
    "\n",
    "from config import Config\n",
    "from models.inp import INP\n",
    "from models.loss import NLL\n",
    "from models.knowledge_corruption import corrupt_knowledge\n",
    "from dataset.utils import setup_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 runs: ['aggressive_align_rT_seed0', 'aggressive_align_rT_seed1', 'aggressive_align_rT_seed2', 'baseline_seed0', 'baseline_seed1', 'baseline_seed2', 'safe_align_rC_seed0', 'safe_align_rC_seed1', 'safe_align_rC_seed2']\n"
     ]
    }
   ],
   "source": [
    "# ---------- Configuration ----------\n",
    "OUTPUT_DIR = 'outputs'\n",
    "MAX_EVAL_BATCHES = 50\n",
    "EVAL_SEED = 42\n",
    "CONTEXT_SIZES = [0, 3, 5, 10]\n",
    "\n",
    "CORRUPTION_REGIMES = {\n",
    "    'clean':      {'regime_str': 'clean',      'sigma_rel': 0.0},\n",
    "    'noisy_low':  {'regime_str': 'noisy_0.1',  'sigma_rel': 0.1},\n",
    "    'noisy_high': {'regime_str': 'noisy_0.3',  'sigma_rel': 0.3},\n",
    "    'permuted':   {'regime_str': 'permuted',   'sigma_rel': 0.0},\n",
    "}\n",
    "\n",
    "# Discover all Step A run dirs that have a checkpoint\n",
    "RUN_NAMES = sorted([\n",
    "    d for d in os.listdir(OUTPUT_DIR)\n",
    "    if os.path.isfile(os.path.join(OUTPUT_DIR, d, 'model_best.pt'))\n",
    "       and os.path.isfile(os.path.join(OUTPUT_DIR, d, 'config.toml'))\n",
    "])\n",
    "print(f'Found {len(RUN_NAMES)} runs: {RUN_NAMES}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(run_dir):\n",
    "    \"\"\"Load trained INP model from a Step A run directory.\"\"\"\n",
    "    config = Config.from_toml(os.path.join(run_dir, 'config.toml'))\n",
    "    config.device = 'cpu'\n",
    "    # Disable knowledge dropout at eval time\n",
    "    config.knowledge_dropout = 0.0\n",
    "\n",
    "    # We need knowledge_input_dim from dataset; for sinusoids abc2 it's always 4\n",
    "    config.knowledge_input_dim = 4\n",
    "\n",
    "    model = INP(config)\n",
    "    state_dict = torch.load(os.path.join(run_dir, 'model_best.pt'), map_location='cpu')\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    return model, config\n",
    "\n",
    "\n",
    "def get_test_dataloader(config):\n",
    "    \"\"\"Build test dataloader matching training config.\"\"\"\n",
    "    _, _, test_dl, _ = setup_dataloaders(config)\n",
    "    return test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_run(run_name):\n",
    "    \"\"\"Evaluate one run under all corruption regimes. Returns list of result dicts.\"\"\"\n",
    "    run_dir = os.path.join(OUTPUT_DIR, run_name)\n",
    "    model, config = load_model(run_dir)\n",
    "    test_dl = get_test_dataloader(config)\n",
    "\n",
    "    nll_func = NLL(reduction='none')  # per-sample IS-NLL\n",
    "\n",
    "    # Set seeds for reproducibility\n",
    "    torch.manual_seed(EVAL_SEED)\n",
    "    np.random.seed(EVAL_SEED)\n",
    "    random.seed(EVAL_SEED)\n",
    "\n",
    "    # Collect batches once (to reuse across corruption regimes)\n",
    "    batches = []\n",
    "    for i, batch in enumerate(test_dl):\n",
    "        if i >= MAX_EVAL_BATCHES:\n",
    "            break\n",
    "        context, target, knowledge, extras = batch\n",
    "        x_target, y_target = target\n",
    "        batches.append((x_target, y_target, knowledge))\n",
    "\n",
    "    # Pre-sample context indices for each batch and each C\n",
    "    # (shared across corruption regimes for variance control)\n",
    "    rng = np.random.RandomState(EVAL_SEED)\n",
    "    batch_context_indices = []\n",
    "    for x_target, _, _ in batches:\n",
    "        n_points = x_target.shape[1]\n",
    "        indices_per_C = {}\n",
    "        for C in CONTEXT_SIZES:\n",
    "            if C == 0:\n",
    "                indices_per_C[C] = np.array([], dtype=int)\n",
    "            else:\n",
    "                indices_per_C[C] = rng.choice(n_points, C, replace=False)\n",
    "        batch_context_indices.append(indices_per_C)\n",
    "\n",
    "    # Evaluate\n",
    "    run_results = []\n",
    "    for mode_name, mode_cfg in CORRUPTION_REGIMES.items():\n",
    "        regime_str = mode_cfg['regime_str']\n",
    "        sigma_rel = mode_cfg['sigma_rel']\n",
    "\n",
    "        nll_per_C = {C: [] for C in CONTEXT_SIZES}\n",
    "\n",
    "        for batch_idx, (x_target, y_target, knowledge) in enumerate(batches):\n",
    "            # Corrupt knowledge ONCE per batch (reuse for all C)\n",
    "            K_corrupted = corrupt_knowledge(knowledge, regime=regime_str, seed=EVAL_SEED + batch_idx)\n",
    "\n",
    "            for C in CONTEXT_SIZES:\n",
    "                idx = batch_context_indices[batch_idx][C]\n",
    "\n",
    "                if C == 0:\n",
    "                    x_ctx = x_target[:, :0, :]  # empty context\n",
    "                    y_ctx = y_target[:, :0, :]\n",
    "                else:\n",
    "                    x_ctx = x_target[:, idx, :]\n",
    "                    y_ctx = y_target[:, idx, :]\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(\n",
    "                        x_ctx, y_ctx, x_target, y_target=None,\n",
    "                        knowledge=K_corrupted\n",
    "                    )\n",
    "                    p_yCc, z_samples, q_z_Cc, q_zCct = outputs[:4]\n",
    "                    nll_val, _, _ = nll_func.get_loss(\n",
    "                        p_yCc, z_samples, q_z_Cc, q_zCct, y_target\n",
    "                    )\n",
    "                    # nll_val: [batch_size] per-sample NLL\n",
    "                    nll_per_C[C].append(nll_val.mean().item())\n",
    "\n",
    "        # Aggregate\n",
    "        result = {\n",
    "            'run_name': run_name,\n",
    "            'run_dir': run_dir,\n",
    "            'seed': int(run_name.split('seed')[-1]) if 'seed' in run_name else -1,\n",
    "            'eval_corruption_mode': mode_name,\n",
    "            'sigma_rel': sigma_rel,\n",
    "        }\n",
    "        for C in CONTEXT_SIZES:\n",
    "            result[f'eval_nll_{C}'] = float(np.mean(nll_per_C[C]))\n",
    "        result['mean_eval_nll'] = float(np.mean(\n",
    "            [result[f'eval_nll_{C}'] for C in CONTEXT_SIZES]\n",
    "        ))\n",
    "\n",
    "        run_results.append(result)\n",
    "\n",
    "        # Save per-run per-mode JSON\n",
    "        json_path = os.path.join(run_dir, f'stepB_{mode_name}.json')\n",
    "        with open(json_path, 'w') as f:\n",
    "            json.dump(result, f, indent=2)\n",
    "\n",
    "    return run_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating: aggressive_align_rT_seed0\n",
      "  clean         mean_nll=42.0457  nll@0=117.9802  nll@3=37.4406  nll@5=14.7310  nll@10=-1.9688\n",
      "  noisy_low     mean_nll=85.4011  nll@0=200.5888  nll@3=82.2076  nll@5=49.1143  nll@10=9.6936\n",
      "  noisy_high    mean_nll=268.1713  nll@0=528.6855  nll@3=269.0284  nll@5=183.3592  nll@10=91.6122\n",
      "  permuted      mean_nll=318.6687  nll@0=676.4164  nll@3=304.2128  nll@5=197.8510  nll@10=96.1947\n",
      "\n",
      "Evaluating: aggressive_align_rT_seed1\n",
      "  clean         mean_nll=35.4595  nll@0=108.6789  nll@3=25.5044  nll@5=10.1731  nll@10=-2.5183\n",
      "  noisy_low     mean_nll=89.6862  nll@0=230.7248  nll@3=71.2310  nll@5=42.6149  nll@10=14.1743\n",
      "  noisy_high    mean_nll=378.4654  nll@0=855.9799  nll@3=310.4139  nll@5=204.6845  nll@10=142.7834\n",
      "  permuted      mean_nll=360.5978  nll@0=798.5223  nll@3=317.2819  nll@5=208.0097  nll@10=118.5772\n",
      "\n",
      "Evaluating: aggressive_align_rT_seed2\n",
      "  clean         mean_nll=39.3868  nll@0=117.9600  nll@3=30.0178  nll@5=11.0919  nll@10=-1.5227\n",
      "  noisy_low     mean_nll=88.2258  nll@0=225.8240  nll@3=75.3905  nll@5=38.3099  nll@10=13.3788\n",
      "  noisy_high    mean_nll=339.8143  nll@0=727.9477  nll@3=286.7864  nll@5=212.5830  nll@10=131.9399\n",
      "  permuted      mean_nll=346.4860  nll@0=772.9759  nll@3=301.5969  nll@5=194.2249  nll@10=117.1462\n",
      "\n",
      "Evaluating: baseline_seed0\n",
      "  clean         mean_nll=41.6771  nll@0=116.9850  nll@3=31.1427  nll@5=18.5438  nll@10=0.0368\n",
      "  noisy_low     mean_nll=84.4049  nll@0=210.7803  nll@3=68.7354  nll@5=46.7457  nll@10=11.3582\n",
      "  noisy_high    mean_nll=277.2620  nll@0=609.1508  nll@3=230.8230  nll@5=170.5987  nll@10=98.4755\n",
      "  permuted      mean_nll=311.3340  nll@0=718.1311  nll@3=258.3279  nll@5=170.7093  nll@10=98.1679\n",
      "\n",
      "Evaluating: baseline_seed1\n",
      "  clean         mean_nll=38.2176  nll@0=114.9822  nll@3=28.1990  nll@5=9.2754  nll@10=0.4138\n",
      "  noisy_low     mean_nll=86.1481  nll@0=229.3774  nll@3=64.2944  nll@5=37.5663  nll@10=13.3545\n",
      "  noisy_high    mean_nll=314.4119  nll@0=676.3483  nll@3=251.5928  nll@5=208.1933  nll@10=121.5133\n",
      "  permuted      mean_nll=343.8255  nll@0=755.9256  nll@3=286.8153  nll@5=210.3109  nll@10=122.2502\n",
      "\n",
      "Evaluating: baseline_seed2\n",
      "  clean         mean_nll=36.1287  nll@0=111.2696  nll@3=27.8559  nll@5=9.4932  nll@10=-4.1038\n",
      "  noisy_low     mean_nll=85.9077  nll@0=210.0104  nll@3=76.9924  nll@5=42.7197  nll@10=13.9083\n",
      "  noisy_high    mean_nll=353.1036  nll@0=755.9651  nll@3=312.4934  nll@5=201.4557  nll@10=142.5000\n",
      "  permuted      mean_nll=341.8580  nll@0=743.1702  nll@3=293.8358  nll@5=200.6252  nll@10=129.8008\n",
      "\n",
      "Evaluating: safe_align_rC_seed0\n",
      "  clean         mean_nll=45.7278  nll@0=121.7375  nll@3=38.6450  nll@5=20.0945  nll@10=2.4342\n",
      "  noisy_low     mean_nll=75.1792  nll@0=191.4327  nll@3=65.1324  nll@5=35.7693  nll@10=8.3823\n",
      "  noisy_high    mean_nll=242.8614  nll@0=560.3592  nll@3=199.6621  nll@5=139.4807  nll@10=71.9438\n",
      "  permuted      mean_nll=241.4859  nll@0=567.6034  nll@3=210.3288  nll@5=134.6750  nll@10=53.3365\n",
      "\n",
      "Evaluating: safe_align_rC_seed1\n",
      "  clean         mean_nll=40.1127  nll@0=115.0842  nll@3=34.5632  nll@5=12.4784  nll@10=-1.6751\n",
      "  noisy_low     mean_nll=88.6297  nll@0=227.7412  nll@3=73.0911  nll@5=43.8827  nll@10=9.8039\n",
      "  noisy_high    mean_nll=307.4860  nll@0=690.5007  nll@3=257.7901  nll@5=183.5139  nll@10=98.1392\n",
      "  permuted      mean_nll=313.1972  nll@0=654.1313  nll@3=286.1556  nll@5=198.3769  nll@10=114.1251\n",
      "\n",
      "Evaluating: safe_align_rC_seed2\n",
      "  clean         mean_nll=41.0748  nll@0=123.5740  nll@3=33.5428  nll@5=8.2598  nll@10=-1.0774\n",
      "  noisy_low     mean_nll=94.1961  nll@0=226.4200  nll@3=85.7440  nll@5=49.4814  nll@10=15.1391\n",
      "  noisy_high    mean_nll=297.1435  nll@0=619.5867  nll@3=269.5104  nll@5=198.3415  nll@10=101.1356\n",
      "  permuted      mean_nll=317.5021  nll@0=677.7699  nll@3=276.0651  nll@5=210.5179  nll@10=105.6555\n",
      "\n",
      "Total result rows: 36\n"
     ]
    }
   ],
   "source": [
    "# ---------- Run evaluation for all checkpoints ----------\n",
    "all_results = []\n",
    "for run_name in RUN_NAMES:\n",
    "    print(f'\\nEvaluating: {run_name}')\n",
    "    results = evaluate_run(run_name)\n",
    "    for r in results:\n",
    "        mode = r['eval_corruption_mode']\n",
    "        print(f\"  {mode:12s}  mean_nll={r['mean_eval_nll']:.4f}  \"\n",
    "              f\"nll@0={r['eval_nll_0']:.4f}  nll@3={r['eval_nll_3']:.4f}  \"\n",
    "              f\"nll@5={r['eval_nll_5']:.4f}  nll@10={r['eval_nll_10']:.4f}\")\n",
    "    all_results.extend(results)\n",
    "\n",
    "print(f'\\nTotal result rows: {len(all_results)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote outputs/stepB_eval.json\n",
      "Wrote outputs/stepB_eval.tsv\n",
      "\n",
      "Sample row:\n",
      "{\n",
      "  \"run_name\": \"aggressive_align_rT_seed0\",\n",
      "  \"run_dir\": \"outputs/aggressive_align_rT_seed0\",\n",
      "  \"seed\": 0,\n",
      "  \"eval_corruption_mode\": \"clean\",\n",
      "  \"sigma_rel\": 0.0,\n",
      "  \"eval_nll_0\": 117.98021793365479,\n",
      "  \"eval_nll_3\": 37.440579771995544,\n",
      "  \"eval_nll_5\": 14.730976581573486,\n",
      "  \"eval_nll_10\": -1.9687858819961548,\n",
      "  \"mean_eval_nll\": 42.045747101306915\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ---------- Export aggregated JSON + TSV ----------\n",
    "agg_json_path = os.path.join(OUTPUT_DIR, 'stepB_eval.json')\n",
    "agg_tsv_path = os.path.join(OUTPUT_DIR, 'stepB_eval.tsv')\n",
    "\n",
    "# JSON\n",
    "with open(agg_json_path, 'w') as f:\n",
    "    json.dump(all_results, f, indent=2)\n",
    "print(f'Wrote {agg_json_path}')\n",
    "\n",
    "# TSV\n",
    "if all_results:\n",
    "    fieldnames = list(all_results[0].keys())\n",
    "    with open(agg_tsv_path, 'w', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames, delimiter='\\t')\n",
    "        writer.writeheader()\n",
    "        for row in all_results:\n",
    "            writer.writerow(row)\n",
    "    print(f'Wrote {agg_tsv_path}')\n",
    "\n",
    "# Quick sanity check\n",
    "print(f'\\nSample row:')\n",
    "print(json.dumps(all_results[0], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 36 rows have correct keys.\n",
      "Files exist: outputs/stepB_eval.json, outputs/stepB_eval.tsv\n",
      "Step B DONE.\n"
     ]
    }
   ],
   "source": [
    "# ---------- Verification ----------\n",
    "expected_keys = {\n",
    "    'run_name', 'run_dir', 'seed', 'eval_corruption_mode', 'sigma_rel',\n",
    "    'eval_nll_0', 'eval_nll_3', 'eval_nll_5', 'eval_nll_10', 'mean_eval_nll',\n",
    "}\n",
    "for r in all_results:\n",
    "    missing = expected_keys - set(r.keys())\n",
    "    assert not missing, f'Missing keys in {r[\"run_name\"]}: {missing}'\n",
    "\n",
    "assert os.path.isfile(agg_json_path), 'stepB_eval.json not found'\n",
    "assert os.path.isfile(agg_tsv_path), 'stepB_eval.tsv not found'\n",
    "print(f'All {len(all_results)} rows have correct keys.')\n",
    "print(f'Files exist: {agg_json_path}, {agg_tsv_path}')\n",
    "print('Step B DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv-radar)",
   "language": "python",
   "name": "venv-radar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
